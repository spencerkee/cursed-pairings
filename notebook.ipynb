{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python dictreader\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# # # Generate the tag mapping\n",
    "# with open('tags_1per.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     relationship_tags = []\n",
    "#     for row in reader:\n",
    "#         if row['name'] == 'Redacted':\n",
    "#             continue\n",
    "#         if row['type'] == 'Relationship':\n",
    "#             relationship_tags.append(row)\n",
    "    \n",
    "#     # Write the relationship tags\n",
    "#     with open('relationship_tags.csv', 'w') as f:\n",
    "#         writer = csv.DictWriter(f, fieldnames=reader.fieldnames)\n",
    "#         writer.writeheader()\n",
    "#         for row in relationship_tags:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "# # Read relationship tags into memory\n",
    "# relationship_tags = {}\n",
    "# with open('relationship_tags.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     for row in reader:\n",
    "#         relationship_tags[row['id']] = row\n",
    "\n",
    "# print(relationship_tags['29'])\n",
    "\n",
    "# # Read the works\n",
    "# with open('works_1per.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     all_tags = []\n",
    "#     for row in reader:\n",
    "#         row_tags = row['tags'].split('+')\n",
    "#         relationship_row_tags = [i for i in row_tags if i in relationship_tags]\n",
    "\n",
    "\n",
    "'''\n",
    "Graph structure:\n",
    "nodes: characters\n",
    "edges: relationships (if they appear in the same work)\n",
    "\n",
    "Iterate over the works.\n",
    "Get all the relationship tags from the work.\n",
    "Skip the works with more than 1 relationship tag. \n",
    "Split the relationship tag on / or & as needed to get the characters.\n",
    "Keep track of a dictionary which is a mapping of (character1, character2) -> number of occurances.\n",
    "Create a graph where the nodes are characters and the edges are relationships.\n",
    "\n",
    "\n",
    "\n",
    "# Create these mappings:\n",
    "# tag id -> tag\n",
    "# character name \n",
    "\n",
    "'''\n",
    "\n",
    "def get_pairing(slash_pairing):\n",
    "    if '/' in slash_pairing and '&' in slash_pairing:\n",
    "        raise ValueError(f'Relationship tag contains both / and & {slash_pairing}')\n",
    "    if '/' not in slash_pairing and '&' not in slash_pairing:\n",
    "        raise ValueError(f'Relationship tag contains neither / or & {slash_pairing}')\n",
    "    if slash_pairing.count('/') > 1 or slash_pairing.count('&') > 1:\n",
    "        # Jack Harkness/Ianto Jones/Toshiko Sato\n",
    "        raise ValueError(f'Relationship tag contains more than one / or & {slash_pairing}')\n",
    "    if '/' in slash_pairing:\n",
    "        return [i.strip() for i in slash_pairing.split('/')]\n",
    "    if '&' in slash_pairing:\n",
    "        return [i.strip() for i in slash_pairing.split('&')]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('tags_1per.csv', \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    pairing_id_to_count = defaultdict(int)\n",
    "    pairing_id_to_row = {}\n",
    "    for ind, row in enumerate(reader):\n",
    "        if row['type'] != 'Relationship':\n",
    "            continue\n",
    "        canonical = row['canonical']\n",
    "        # TODO Handle redacted merging better\n",
    "        # if row['name'] == 'Redacted' and canonical == 'false':\n",
    "        #     pairing_id_to_count[row['merger_id']] += int(row['cached_count'])\n",
    "        #     continue\n",
    "\n",
    "        if int(row['cached_count']) == 0:\n",
    "            continue\n",
    "\n",
    "        # print(row)\n",
    "        if canonical == 'true':\n",
    "            pairing_id_to_row[row['id']] = row\n",
    "            pairing_id_to_count[row['id']] += int(row['cached_count'])\n",
    "        else:\n",
    "            pairing_id_to_count[row['merger_id']] += int(row['cached_count'])\n",
    "        # if ind > 50:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11393\n",
      "12773\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "for pairing_id, count in pairing_id_to_count.items():\n",
    "    if pairing_id not in pairing_id_to_row:\n",
    "        continue\n",
    "    relationship_name = pairing_id_to_row[pairing_id]['name']\n",
    "    try:\n",
    "        characters = get_pairing(relationship_name)\n",
    "    except ValueError as e:\n",
    "        # Print\n",
    "        # print(e)\n",
    "        continue\n",
    "    character1, character2 = characters\n",
    "    # TODO Characters can have the same name\n",
    "    G.add_node(character1)\n",
    "    G.add_node(character2)\n",
    "    G.add_edge(character1, character2, weight=count)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "# Print all edges which do not have a weight\n",
    "\n",
    "def get_edge_attributes(G, name):\n",
    "    # ...\n",
    "    edges = G.edges(data=True)\n",
    "    return edges\n",
    "\n",
    "# Check for weight=0 edges\n",
    "var = get_edge_attributes(G, 'weight')\n",
    "for edge in var:\n",
    "    if edge[2]['weight'] == 0:\n",
    "        print(edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 11393/11393 [00:00<00:00, 12749.68it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import random\n",
    "\n",
    "# print(G.edges)\n",
    "\n",
    "# Generate a synthetic graph (you can replace this with your own graph)\n",
    "# G = nx.erdos_renyi_graph(n=100, p=0.1)\n",
    "# G = nx.fast_gnp_random_graph(n=100, p=0.5)\n",
    "# for (u, v) in G.edges():\n",
    "#     G.edges[u,v]['weight'] = random.randint(0,10)\n",
    "\n",
    "# Precompute probabilities and generate walks\n",
    "# 1:52 with dim=64, walk=10, num_walks=10, workers=4\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=10, num_walks=10, workers=4, quiet=False)\n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Retrieve the embeddings for all nodes\n",
    "embeddings = {node: model.wv[node] for node in G.nodes()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least cursed pairings (in terms of vector distance)\n",
      "[(1.0, 'Wrong', 'Wrong'),\n",
      " (1.0, 'Willow Rosenberg', 'Willow Rosenberg'),\n",
      " (1.0, 'Vince Noir', 'Vince Noir'),\n",
      " (1.0, 'Uchiha Sasuke', 'Uchiha Sasuke'),\n",
      " (1.0, 'Tony Stark', 'Tony Stark')]\n",
      "Least cursed (unique) pairings (in terms of vector distance)\n",
      "[(0.99957216, 'Anakin Skywalker', 'Padmé Amidala'),\n",
      " (0.999569, 'Tarrant Hightopp', 'Alice Kingsleigh'),\n",
      " (0.9995467, 'Blair Waldorf', 'Chuck Bass'),\n",
      " (0.9994836, 'L', 'Yagami Light'),\n",
      " (0.9994822, 'Noel Fielding', 'Julian Barratt')]\n",
      "Most cursed pairings (in terms of vector distance)\n",
      "[(0.17784959, 'Tony Stark', 'Jake Jensen'),\n",
      " (0.17772518, 'Ianto Jones', 'The Stig'),\n",
      " (0.16101564, 'Benton Fraser', 'Dale Cooper'),\n",
      " (0.12542525, 'Jack Harkness', 'Jack Sparrow'),\n",
      " (0.12244934, 'Undisclosed', 'Jean-Luc Picard')]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = []\n",
    "for node1, node2 in G.edges:\n",
    "    cosine_similarities.append((model.wv.similarity(node1, node2), node1, node2))\n",
    "cosine_similarities.sort(reverse=True)\n",
    "from pprint import pprint\n",
    "print('Least cursed pairings (in terms of vector distance)')\n",
    "pprint(cosine_similarities[:5])\n",
    "print('Least cursed (unique) pairings (in terms of vector distance)')\n",
    "pprint([i for i in cosine_similarities if i[1] != i[2]][:5])\n",
    "print('Most cursed pairings (in terms of vector distance)')\n",
    "pprint(cosine_similarities[-5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
