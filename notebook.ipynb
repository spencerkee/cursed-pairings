{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python dictreader\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# # # Generate the tag mapping\n",
    "# with open('tags_1per.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     relationship_tags = []\n",
    "#     for row in reader:\n",
    "#         if row['name'] == 'Redacted':\n",
    "#             continue\n",
    "#         if row['type'] == 'Relationship':\n",
    "#             relationship_tags.append(row)\n",
    "    \n",
    "#     # Write the relationship tags\n",
    "#     with open('relationship_tags.csv', 'w') as f:\n",
    "#         writer = csv.DictWriter(f, fieldnames=reader.fieldnames)\n",
    "#         writer.writeheader()\n",
    "#         for row in relationship_tags:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "# # Read relationship tags into memory\n",
    "# relationship_tags = {}\n",
    "# with open('relationship_tags.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     for row in reader:\n",
    "#         relationship_tags[row['id']] = row\n",
    "\n",
    "# print(relationship_tags['29'])\n",
    "\n",
    "# # Read the works\n",
    "# with open('works_1per.csv', \"r\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     all_tags = []\n",
    "#     for row in reader:\n",
    "#         row_tags = row['tags'].split('+')\n",
    "#         relationship_row_tags = [i for i in row_tags if i in relationship_tags]\n",
    "\n",
    "\n",
    "'''\n",
    "Graph structure:\n",
    "nodes: characters\n",
    "edges: relationships (if they appear in the same work)\n",
    "\n",
    "Iterate over the works.\n",
    "Get all the relationship tags from the work.\n",
    "Skip the works with more than 1 relationship tag. \n",
    "Split the relationship tag on / or & as needed to get the characters.\n",
    "Keep track of a dictionary which is a mapping of (character1, character2) -> number of occurances.\n",
    "Create a graph where the nodes are characters and the edges are relationships.\n",
    "\n",
    "\n",
    "\n",
    "# Create these mappings:\n",
    "# tag id -> tag\n",
    "# character name \n",
    "\n",
    "'''\n",
    "\n",
    "def get_pairing(slash_pairing):\n",
    "    if '/' in slash_pairing and '&' in slash_pairing:\n",
    "        raise ValueError(f'Relationship tag contains both / and & {slash_pairing}')\n",
    "    if '/' not in slash_pairing and '&' not in slash_pairing:\n",
    "        raise ValueError(f'Relationship tag contains neither / or & {slash_pairing}')\n",
    "    if slash_pairing.count('/') > 1 or slash_pairing.count('&') > 1:\n",
    "        # Jack Harkness/Ianto Jones/Toshiko Sato\n",
    "        raise ValueError(f'Relationship tag contains more than one / or & {slash_pairing}')\n",
    "    if '/' in slash_pairing:\n",
    "        return [i.strip() for i in slash_pairing.split('/')]\n",
    "    if '&' in slash_pairing:\n",
    "        return [i.strip() for i in slash_pairing.split('&')]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('tags_1per.csv', \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    pairing_id_to_count = defaultdict(int)\n",
    "    pairing_id_to_row = {}\n",
    "    for ind, row in enumerate(reader):\n",
    "        if row['name'] == 'Redacted' or row['type'] != 'Relationship':\n",
    "            continue\n",
    "        canonical = row['canonical']\n",
    "        # print(row)\n",
    "        if canonical == 'true':\n",
    "            pairing_id_to_row[row['id']] = row\n",
    "            pairing_id_to_count[row['id']] += int(row['cached_count'])\n",
    "        else:\n",
    "            pairing_id_to_count[row['merger_id']] += int(row['cached_count'])\n",
    "        # if ind > 50:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13495\n",
      "15445\n",
      "{'Sam Winchester': {'weight': 11301}, 'John Winchester': {'weight': 507}, 'Cassie Robinson': {'weight': 313}, 'Jared Padalecki': {'weight': 57}, 'Bela Talbot': {'weight': 190}, 'Other(s)': {'weight': 936}, 'Castiel': {'weight': 10590}, 'Ruby': {'weight': 86}, 'Jo Harvelle': {'weight': 781}, 'Bobby Singer': {'weight': 40}, 'Claire Littleton': {'weight': 0}, 'Paul Callan': {'weight': 11}, 'Shane McCutcheon': {'weight': 0}, 'Willow Rosenberg': {'weight': 5}, 'Ellen Harvelle': {'weight': 53}, 'Luna Lovegood': {'weight': 3}, 'Faith Lehane': {'weight': 107}, 'Alastair': {'weight': 356}, 'ZoÃ« Washburne': {'weight': 0}, 'Christian Kane': {'weight': 3}, 'Impala': {'weight': 179}, 'Anna Milton': {'weight': 286}, 'Hannibal King': {'weight': 2}, 'John Sheppard': {'weight': 17}, 'Hermione Granger': {'weight': 91}, 'Veronica Mars': {'weight': 11}, 'River Tam': {'weight': 2}, 'Carmen Porter': {'weight': 39}, 'Jack Harkness': {'weight': 53}, 'Kaylee Frye': {'weight': 6}, 'Lucifer': {'weight': 459}, 'Xander Harris': {'weight': 17}, 'Donna Noble': {'weight': 0}, 'Jeeves Tremor': {'weight': 0}, 'Chloe Sullivan': {'weight': 113}, 'Nymphadora Tonks': {'weight': 7}, 'John Constantine': {'weight': 62}, 'Malcolm Reynolds': {'weight': 11}, 'Andy Gallagher': {'weight': 7}, 'Dick Grayson': {'weight': 6}, 'Debra Morgan': {'weight': 0}, 'Grace Choi': {'weight': 0}, 'Jason Todd': {'weight': 3}, 'Jessica Moore': {'weight': 67}, 'Layla Rourke': {'weight': 9}, 'Lenore': {'weight': 5}, 'Rhonda Hurley': {'weight': 66}, 'Roy Harper': {'weight': 0}, 'Stephanie Brown': {'weight': 0}, 'Tessa': {'weight': 35}, 'Uriel': {'weight': 4}, 'Azazel': {'weight': 27}, 'Starla': {'weight': 1}, 'Risa': {'weight': 17}, 'Ash': {'weight': 31}, 'Pamela Barnes': {'weight': 32}, 'Lyla Garrity': {'weight': 0}, 'Tim Riggins': {'weight': 1}, 'Jimmy Novak': {'weight': 15}, 'Michael': {'weight': 474}, 'Angela Dodson': {'weight': 1}, 'Lisa Braeden': {'weight': 1797}, 'Original Character(s)': {'weight': 212}, 'Jayne Cobb': {'weight': 0}, 'Bella Swan': {'weight': 25}, 'Cordelia Chase': {'weight': 3}, 'Lilly Kane': {'weight': 1}, 'Tara Maclay': {'weight': 5}, 'Susan Pevensie': {'weight': 1}, 'Mohinder Suresh': {'weight': 1}, 'Laura Cadman': {'weight': 1}, 'Clark Kent': {'weight': 2}, 'Logan Echolls': {'weight': 0}, 'Dean Winchester': {'weight': 73}, 'Gabriel': {'weight': 1306}, 'Nancy Botwin': {'weight': 0}, 'Undisclosed': {'weight': 3}, 'Derek Reese': {'weight': 0}, 'Logan (X-Men)': {'weight': 7}, 'Sam Wesson': {'weight': 41}, 'Emily Prentiss': {'weight': 3}, 'Gordon Walker': {'weight': 29}, 'Erica Cartwright': {'weight': 0}, 'Amanda Heckerling': {'weight': 6}, 'Nick Boyle': {'weight': 3}, 'Harry Potter': {'weight': 197}, 'Victor Henriksen': {'weight': 89}, 'GLaDOS': {'weight': 0}, 'Charlie Eppes': {'weight': 0}, 'Kate Moreau': {'weight': 0}, 'Sirius Black': {'weight': 1}, 'Wendy Watson': {'weight': 0}, 'Evan Lorne': {'weight': 17}, 'Tony Stark': {'weight': 54}, 'Neal Caffrey': {'weight': 15}, 'Timothy McGee': {'weight': 2}, 'Michael Westen': {'weight': 1}, 'Caleb Danvers': {'weight': 3}, 'Lana Lang': {'weight': 0}, 'Ronon Dex': {'weight': 10}, 'Noah Puckerman': {'weight': 2}, 'Maurice Boscorelli': {'weight': 3}, 'Balthazar': {'weight': 55}, 'Peter Bishop': {'weight': 1}, 'Quinn Fabray': {'weight': 1}, 'Alpha Vampire': {'weight': 3}, 'War': {'weight': 1}, 'Mary Winchester': {'weight': 229}, 'Buffy Summers': {'weight': 215}, 'Chris Pine': {'weight': 1}, 'Andrea Barr': {'weight': 0}}\n",
      "{'Dean Winchester': {'weight': 11301}, 'Jessica Moore': {'weight': 5857}, 'Jensen Ackles': {'weight': 69}, 'Other(s)': {'weight': 334}, 'Ruby': {'weight': 1391}, 'John Winchester': {'weight': 332}, 'Jo Harvelle': {'weight': 200}, 'Faith Lehane': {'weight': 19}, 'Castiel': {'weight': 5497}, 'Sarah Blake': {'weight': 350}, 'River Tam': {'weight': 18}, 'Impala': {'weight': 10}, 'Buffy Summers': {'weight': 15}, 'Ginny Weasley': {'weight': 13}, 'Ellen Harvelle': {'weight': 10}, 'Gabriel': {'weight': 717}, 'Jayne Cobb': {'weight': 3}, 'Dawn Summers': {'weight': 38}, 'Oliver Wood': {'weight': 3}, 'Bela Talbot': {'weight': 45}, 'Andy Gallagher': {'weight': 12}, 'Warren Peace': {'weight': 1}, 'Ronon Dex': {'weight': 4}, 'Brigitte Fitzgerald': {'weight': 1}, 'Pamela Barnes': {'weight': 14}, 'Tim Riggins': {'weight': 1}, 'Bobby Singer': {'weight': 72}, 'Ava Wilson': {'weight': 8}, 'Harry Dresden': {'weight': 3}, 'Original Character(s)': {'weight': 229}, 'Gordon Walker': {'weight': 7}, 'Willow Rosenberg': {'weight': 4}, 'Claire Littleton': {'weight': 0}, 'Anna Milton': {'weight': 32}, 'Chloe Sullivan': {'weight': 33}, 'Lucifer': {'weight': 3918}, 'Michael Scofield': {'weight': 1}, 'Undisclosed': {'weight': 2}, 'Harry Potter': {'weight': 102}, 'Sam Winchester': {'weight': 69}, 'Anita \"Needy\" Lesnicki': {'weight': 0}, 'Meg Masters': {'weight': 112}, 'Connor (AtS)': {'weight': 4}, 'Jake Talley': {'weight': 0}, 'Tobias Beecher': {'weight': 0}, 'Betty Suarez': {'weight': 1}, 'Don Eppes': {'weight': 0}, 'Lenore': {'weight': 11}, 'Hermione Granger': {'weight': 30}, 'Becky Rosen': {'weight': 49}, 'Lana Lang': {'weight': 4}, 'Jimmy Novak': {'weight': 59}, 'Lando Calrissian': {'weight': 1}, 'Kira Ford': {'weight': 0}, 'Claire Redfield': {'weight': 1}, 'Sparrow Jennings': {'weight': 3}, 'Chuck Bartowski': {'weight': 2}, 'Charlie Crews': {'weight': 0}, 'Brittany S. Pierce': {'weight': 0}, 'Jack Harkness': {'weight': 22}, 'Jared Padalecki': {'weight': 19}, 'Mary Winchester': {'weight': 128}, 'Adam Milligan': {'weight': 78}, 'Nyota Uhura': {'weight': 1}, 'Genevieve Cortese': {'weight': 14}}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "for pairing_id, count in pairing_id_to_count.items():\n",
    "    if pairing_id not in pairing_id_to_row:\n",
    "        continue\n",
    "    relationship_name = pairing_id_to_row[pairing_id]['name']\n",
    "    try:\n",
    "        characters = get_pairing(relationship_name)\n",
    "    except ValueError as e:\n",
    "        # Print\n",
    "        # print(e)\n",
    "        continue\n",
    "    character1, character2 = characters\n",
    "    # TODO Characters can have the same name\n",
    "    G.add_node(character1)\n",
    "    G.add_node(character2)\n",
    "    G.add_edge(character1, character2, weight=count)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "print(G['Dean Winchester'])\n",
    "print(G['Sam Winchester'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities:   2%|â         | 271/13495 [00:00<00:09, 1431.53it/s]/home/codespace/.python/current/lib/python3.12/site-packages/node2vec/node2vec.py:143: RuntimeWarning: invalid value encountered in divide\n",
      "  d_graph[source][self.FIRST_TRAVEL_KEY] = first_travel_weights / first_travel_weights.sum()\n",
      "Computing transition probabilities: 100%|ââââââââââ| 13495/13495 [00:01<00:00, 11643.79it/s]\n",
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Total of weights must be finite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/codespace/.local/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/codespace/.local/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/codespace/.local/lib/python3.12/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/codespace/.python/current/lib/python3.12/site-packages/node2vec/parallel.py\", line 59, in parallel_generate_walks\n    walk_to = random.choices(walk_options, weights=probabilities)[0]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/codespace/.python/current/lib/python3.12/random.py\", line 485, in choices\n    raise ValueError('Total of weights must be finite')\nValueError: Total of weights must be finite\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnode2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node2Vec\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate a synthetic graph (you can replace this with your own graph)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# G = nx.erdos_renyi_graph(n=100, p=0.1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Precompute probabilities and generate walks\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# num_walks=20 is like 4.5 seconds\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m node2vec \u001b[38;5;241m=\u001b[39m \u001b[43mNode2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Embed nodes\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m node2vec\u001b[38;5;241m.\u001b[39mfit(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/node2vec/node2vec.py:74\u001b[0m, in \u001b[0;36mNode2Vec.__init__\u001b[0;34m(self, graph, dimensions, walk_length, num_walks, p, q, weight_key, workers, sampling_strategy, quiet, temp_folder, seed)\u001b[0m\n\u001b[1;32m     71\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precompute_probabilities()\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_walks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/node2vec/node2vec.py:159\u001b[0m, in \u001b[0;36mNode2Vec._generate_walks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Split num_walks for each worker\u001b[39;00m\n\u001b[1;32m    157\u001b[0m num_walks_lists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_walks), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers)\n\u001b[0;32m--> 159\u001b[0m walk_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_generate_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_WALKS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWALK_LENGTH_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEIGHBORS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROBABILITIES_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_TRAVEL_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m walks \u001b[38;5;241m=\u001b[39m flatten(walk_results)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m walks\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Total of weights must be finite"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Generate a synthetic graph (you can replace this with your own graph)\n",
    "# G = nx.erdos_renyi_graph(n=100, p=0.1)\n",
    "\n",
    "# Precompute probabilities and generate walks\n",
    "# num_walks=20 is like 4.5 seconds\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=20, workers=4, weight_key='weight')\n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Retrieve the embeddings for all nodes\n",
    "embeddings = {node: model.wv[node] for node in G.nodes()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "print(G.nodes())\n",
    "\n",
    "# # Example: Print the embedding for node 0\n",
    "# print(\"Embedding for Node 0:\", embeddings[0])\n",
    "\n",
    "# # Print cosine similarity between node 0 and node 1\n",
    "# cosine_similarity = model.wv.similarity('0', '1')\n",
    "# print(\"Cosine similarity between Node 0 and Node 1:\", cosine_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
